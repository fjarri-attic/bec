\documentclass[12pt,notitlepage]{report}
\usepackage{indentfirst}
\usepackage[pdftex]{graphicx}
\usepackage{subfig}
\usepackage{amsmath}

\title{Two-component BEC dynamics calculations using split-step Fourier method}
\author{Bogdan Opanchuk}

\begin{document}
\maketitle

\section*{Natural units}

Before we start doing any calculations, a transformation to dimensionless units should be defined. It will significantly increase readability of equations and facilitate various estimations.

There are several ways to do it; since we are working with the harmonic potential, the obvious variant is to use the parameters of harmonic oscillator as new units, taking into account the usual symmetry $\omega_x = \omega_y = \omega_\rho$ which exists in experiments:
\[ l_\rho =  \sqrt{\frac{\hbar}{m\omega_\rho}},\, t_\rho = \frac{1}{\omega_\rho},\, E_\rho = \hbar \omega_\rho. \]

Dimensionless variables will be mainly used throughout the article, so, for the sake of readability, they will be explicitly marked with primes only when they can be confused with variables in real units. In other places all variables should be considered dimensionless unless explicitly specified as real. For example, the transformation of coordinates will look like:
\[ x = x^\prime l_\rho,\, y = y^\prime l_\rho,\, z = z^\prime l_\rho. \]

Wave function can be transformed in different ways depending on the normalisation. We will use the transformation that keeps the integral of wave function over space equal to number of particles in the system:
\[ \Psi = \Psi^\prime / l_\rho^\frac{3}{2}. \]

\section*{Thomas-Fermi approximation}

We are looking for steady state of the system with pseudopotential model hamiltonian (in real units):
\[ 
\hat{H} = -\frac{\hbar^2}{2m} \frac{\partial^2}{\partial \mathbf{r}^2} + \\
V(\mathbf{r}) + g_{11} \vert \Psi(\mathbf{r}) \vert^2,
\]
\[ g_{11} = \frac{4 \pi \hbar^2 a_{11}}{m}, \]
\[ V(\mathbf{r}) = \frac{m}{2} \left( \omega_x^2 x^2 + \omega_y^2 y^2 + \omega_z^2 z^2 \right). \]
where $V(\mathbf{r})$ is the potential energy for parabolic trap, $g_{11}$ is the interaction coefficient and $a_{11}$ is the scattering length for atoms in non-excited state. In natural units:
\[
\hat{H} = -\frac{1}{2} \frac{\partial^2}{\partial \mathbf{r}^2} + 
\frac{1}{2} \left( x^2 + y^2 + \lambda^{-2} z^2 \right) + g_{11} \vert \Psi(\mathbf{r}) \vert^2,
\]
where
\[ \lambda = \frac{\omega_\rho}{\omega_z},\, g_{11} = \frac{4 \pi a_{11}}{l_\rho}. \]

The steady state should satisfy the Gross-Pitaevskii equation:
\[ \hat{H} \Psi = \mu \Psi. \]
To get the first approximation of the state function, we consider the kinetic term to be small as compared to other terms and omit it. The conditions for this operation to be valid will be determined later in this section. Thus we get the simple equation:
\[ \left( V(\mathbf{r}) + g_{11} \vert \Psi(\mathbf{r}) \vert^2 \right) \Psi(\mathbf{r}) = \mu \Psi(\mathbf{r}), \]
which leads us to the state function:
\[ \vert \Psi(\mathbf{r}) \vert^2 = \frac{1}{g_{11}} \max \left( \mu - V(\mathbf{r}), 0 \right). \]
The condition for $V(\mathbf{r})$ defines the shape of the condensate - it is the ellipsoid with the following radii:
\[ r_x = r_y = \sqrt{2\mu},\, r_z = \lambda \sqrt{2\mu}. \]

Using the normalisation condition for the steady state function gives us the connection between the number of atoms in the condensate and the chemical potential:
\[ \int\limits_{V} \vert \Psi(\mathbf{r}) \vert^2 dV = N, \]
\[ \mu = \left( \frac{15 N g_{11}}{16 \pi \lambda \sqrt{2}} \right)^{\frac{2}{5}}, \]
or, in real units:
\[ 
\mu = \left( \frac{15 N}{8 \pi} \right)^\frac{2}{5} 
\left( \frac{m \bar{\omega}^2}{2} \right)^\frac{3}{5}
{g_{11}}^\frac{2}{5},
\]
where $\bar{\omega} = \sqrt[3]{\omega_x \omega_y \omega_z}$.

Now we can roughly estimate the conditions necessary to drop the kinetic term from equation. Substitution of the approximate solution and calculation of the second derivative gives us the following inequation:
\[
\left( 
	\frac{2 + \lambda^{-2}}{2 \sqrt{\mu - V(\mathbf{r})}} +
	\frac{\left( x + y + \lambda^{-2}z \right)^2}{4 \left( \mu - V(\mathbf{r}) \right)^{\frac{3}{2}}} 
\right) \ll
\mu \sqrt{\mu - V(\mathbf{r})}.
\]
In the experiments $\lambda$ is usually of the order of ten, so we can drop terms with $\lambda^{-2}$. Therefore, near the centre of the condensate we this inequation simplifies to $\mu \gg 1$, which, in turn gives us the condition:
\[ \frac{N a_{11}}{\lambda l_\rho} \gg 1. \]

On the other hand, near the edges the left-hand side of the inequation converges to infinity, while the right-hand side equals zero. This means that near the edges of the condensate Thomas-Fermi approximation fails regardless of the conditions. Fortunately, the density of the particles there is low, so we can estimate the width $h$ of the "belt" where our first approximation of the state function is significantly incorrect. If it happens to be small as compared to the size of the condensate, the approximation can be considered valid.

The first term at the left-hand side of the inequation converges to infinity slower than the second one and can be dropped. Then, for the sake of simplicity, we consider two of three coordinates to be zero and the third one to equal $r - h$, where $r$ is the corresponding radius of the condensate. After replacing "$\ll$" by "$\approx$" and assuming $h$ to be small as compared to $r$, we obtain:
\[ h_x \approx \frac{2}{\sqrt{2 \mu}},\, h_z \approx \frac{2}{\lambda \sqrt{2 \mu}}. \]
They have to be much smaller than corresponding radii, which gives us:
\[ x:\: \mu \gg 1,\, z:\: \mu \gg \lambda^{-2}. \]
The former condition is the same as for the centre of the condensate, but the latter one is much less strict. Therefore, we have only one condition justifying the application of Thomas-Fermi approximation: $\mu \gg 1$.
 
Let us use some real-life experimental parameters and check how well Thomas-Fermi approximation works. For three-dimensional trap with frequencies $f_x = f_y = 97.6 \textrm{ Hz}$ and $f_x = 11.96 \textrm{ Hz}$ and $10^5$ rubidium atoms (which have scattering length $a_{11} = 100.4 a_0$, where $a_0$ is Bohr radius) we have $\mu \approx 7.56$. This means that Thomas-Fermi approximation produces solution which is close to the real one. But for lower amount of atoms, say $10^4$, we get $\mu \approx 3.02$, which is a sign that the we have reached the limit of the approximation's applicability. Therefore, for low amounts of atoms, Thomas-Fermi approximation must be used with care.

\section*{Steady state calculation}

The steady state obtained using Thomas-Fermi approximation is good for estimation purposes, but not for real-life calculations - for example, it does not have continuous first derivative everywhere (namely, near the edges of the condensate). That is why we have to employ numerical calculations in order to find precise (to a certain extent) solution of the Gross-Pitevskii equation. One of the possible ways, the propagation in imaginary time using split-step Fourier method, will be described in this section.

The idea of the propagation in imaginary time is that propagating the system state using the time-dependent GPE but with substitution $t \rightarrow \tau = it$ diminishes energy of the system, so after the sufficient amount of time this propagation will lead us to steady state. The rigorous proof of this method can be found in \cite{gpe_ngf}, but there is a simple "hand-waving" explanation. It assumes the superposition principle works for GPE, though it does not because of the nonlinearity.

Let us say we have the system with Hamiltonian $\hat{H}$, whose eigenvalues are $\mu_1 < \mu_2 < ...$. They do not have to correspond to real states of BEC, we just know that this Hamiltonian must have discrete spectre (because of the form of the potential) and the lowest eigenvalue corresponds to steady state we want to find. The steady solution of time-dependent GPE
\[ i \frac{\partial \Psi}{\partial t} = \hat{H} \Psi \]
then looks like
\[ \Psi(\mathbf{r}, t) = \sum_k e^{-i \mu_k t} f_k(\mathbf{r}). \]
We can use Hamiltonian to propagate the solution in time:
\[ 
\Psi(t + dt) \simeq \Psi(t) + \frac{\partial \Psi}{\partial t} dt =
\Psi(t) + \frac{dt}{i} \hat{H} \Psi(t).
\]

Now consider the substitution $t \rightarrow \tau = it$; after it the steady solution will become fading, with higher-energy components fading faster:
\begin{equation}
\label{split_step_steady_state:general_solution_imaginary_time}
\Psi(\mathbf{r}, \tau) = \sum_k e^{-\mu_k \tau} f_k(\mathbf{r}).
\end{equation}
Therefore, if we take some random initial solution and propagate it for a sufficient amount of time, higher-energy components will eventually die out (in comparison with the lowest-energy state) and leave us with desired steady state:
\begin{equation}
\label{split_step_steady_state:iterative_process}
\Psi(\tau + d\tau) \simeq \Psi(\tau) - d\tau \hat{H} \Psi(\tau).
\end{equation}
The state obtained from Thomas-Fermi approximated GPE can be taken as an initial one, since it is rather close to the desired one (and, therefore, higher-energy components are already quite small).

Since the energy will decrease exponentially after each step and the precision of numerical calculations is limited, renormalisation after each step will be required. Known total number of atoms in steady state serves best in this case (because we will have to renormalise the final steady state anyway):
\[ \int\limits_V \vert \Psi(\tau, \mathbf{r}) \vert^2 dV = N. \]

Propagation should be terminated when the total energy of the state stops changing (that is, only one component with the lowest energy is left out). So, we need to calculate the total energy after each step:
\[ E(\psi) = \int\limits_V \Psi^\dagger \left(
-\frac{\nabla^2}{2} + V(\mathbf{r}) + \frac{g_{11}}{2} \vert \Psi(\mathbf{r}) \vert^2 \right) \Psi dV \]
and compare it to the previous value.

Now how do we propagate the state of the system? There are a lot of possibilities, one of which is split-step Fourier method. It is rather simple and can be effectively parallelised, which means a good scaling and low computation times. 

The propagation in imaginary time can be described as:
\[ \Psi(\tau + d\tau, \mathbf{r}) \simeq \exp ( -d\tau \hat{H} ) \Psi(\tau, \mathbf{r}). \]
The idea of split-step Fourier method is to separate the execution of different parts of Hamiltonian:
\begin{equation}
\label{split_step_steady_state:splitted_propagation}
\psi(\tau + d\tau, \mathbf{r}) \simeq \exp(d\tau \hat{D}) \exp(d\tau \hat{N}) \psi(\tau, \mathbf{r}),
\end{equation}
where $\hat{D}$ and $\hat{N}$ are chosen so that they could be executed most conveniently in Fourier and spatial domains correspondingly. For our Hamiltonian
\[ 
\hat{H} = -\frac{1}{2} \frac{\partial^2}{\partial \mathbf{r}^2} +
V(\mathbf{r}) + g_{11} \vert \Psi(\mathbf{r}) \vert^2,
\]
it means that
\[
\hat{D} = \frac{1}{2} \frac{\partial^2}{\partial \mathbf{r}^2},\,
\hat{N} = -\left( V(\mathbf{r}) + g_{11} \vert \Psi(\mathbf{r}) \vert^2 \right).
\]
The spatial derivative is a simple multiplication in Fourier domain, so the propagation can be performed straightforwardly:
\[
\Psi(\tau + d\tau, \mathbf{r}) \simeq \left\{ \hat{F}^{-1} \exp \left[ d\tau \hat{D}(i\omega) \right] \hat{F} \right\}
\exp(d\tau \hat{N}) \Psi(\tau, \mathbf{r}).
\]
Here $\hat{D}(i\omega)$ is obtained by replacing differential operator by $i \omega$, where $\omega$ is a frequency in Fourier domain.

In order to improve the accuracy of the method, equation \ref{split_step_steady_state:splitted_propagation} can be rewritten as
\[
\Psi(\tau + d\tau, \mathbf{r}) \simeq \exp \left( \frac{d\tau}{2} \hat{D} \right)
\exp \left( \int\limits^{\tau + d\tau}_\tau \hat{N} (\tau^\prime) d\tau^\prime \right)
\exp \left( \frac{d\tau}{2} \hat{D} \right) \Psi(\tau, \mathbf{r}).
\]
This method is called the symmetrized split-step Fourier method. Integral can be evaluated either by approximating it with $d\tau\hat{N}$ or by using more accurate method, like trapezoidal rule
\[
\int\limits^{\tau + d\tau}_\tau \hat{N} (\tau^\prime) d\tau^\prime \simeq
\frac{d\tau}{2} \left( \hat{N}(\tau) + \hat{N}(\tau + d\tau) \right).
\]
Since the value of $\hat{N}(\tau + d\tau)$ is unknown at the time of the calculation (it is performed in the middle of the step), an iterative procedure is necessary.

\section*{Two-component evolution}

Now when we have got the steady state for one-component system, it is the time to start the simulation of two-component system. The initial state for the component $\vert1\rangle$ is the one-component steady state, and for $\vert2\rangle$ the initial state equals to zero.

The evolution of the system is described by coupled Gross-Pitaevskii equations. They can contain different terms depending on which features of the system we need to take into account. Basic form can be found in many sources, i.e. \cite{pitaevskii_bec}; with the addition of loss terms it looks like (in real units):
\[ i \hbar \frac{\partial \Psi_1}{\partial t} = \left(
	-\frac{\hbar^2\nabla^2}{2m} + V_1(\mathbf{r}) +
	g_{11} \vert \Psi_1 \vert^2 + g_{12} \vert \Psi_2 \vert^2 - i \hbar \Gamma_1
\right) \Psi_1 + \frac{\hbar \Omega}{2}e^{i \omega t} \Psi_2, \]
\[ i \hbar \frac{\partial \Psi_2}{\partial t} = \left(
	-\frac{\hbar^2\nabla^2}{2m} + V_2(\mathbf{r}) +
	g_{12} \vert \Psi_1 \vert^2 + g_{22} \vert \Psi_2 \vert^2 - i \hbar \Gamma_2
\right) \Psi_2 + \frac{\hbar \Omega}{2}e^{i \omega t} \Psi_1 - \hbar \Delta \Psi_2. \]

Let us now explain each term in this system. $V_1$ and $V_2$ stand for the external potential (which, in general, is different for each component). For our purposes we can consider $V_1 = V_2 = V_{ext}$ (symmetric trapping), where $V_{ext}$ is a trap potential. Interaction coefficients $g_{11}$, $g_{12}$ and $g_{22}$ depend on corresponding scattering lengths:
\[ g_{ij} = \frac{4 \pi \hbar^2 a_{ij}}{m}. \]
For rubidium, according to the latest experimental data (\cite{PhysRevLett.99.190402}), $a_{11} = 100.40\ a_0$, $a_{22} = 95.00\ a_0$ and $a_{12} = 97.66\ a_0$ where $a_0$ is the Bohr radius. $\Gamma_1 = (\gamma_{111} n_1^2 + \gamma_{12} n_2) / 2$ and $\Gamma_2 = (\gamma_{22} n_2 + \gamma_{12} n_1) / 2$, where $n_1$ and $n_2$ stand for the densities of components, are responsible for two- and three-body loss processes. Loss rates $\gamma$ can be found in \cite{PhysRevLett.99.190402} and \cite{PhysRevLett.79.337}:
\[ \gamma_{111} = 5.4(11) \times 10^{-30}\ \textrm{cm}^6/\textrm{s}, \]
\[ \gamma_{12} = 0.780(19) \times 10^{-13}\ \textrm{cm}^3/\textrm{s}, \]
\[ \gamma_{22} = 1.194(19) \times 10^{-13}\ \textrm{cm}^3/\textrm{s}. \]
$\Delta$ is a detuning frequency and depends on experimental conditions.

$\Omega$ is a constant for state transitions due to external oscillating magnetic field, for example, during $\frac{\pi}{2}$-pulses. Since these pulses act for a short amount of time (as compared to the time scale of the system), we can apply corresponding matrix instantaneously instead of explicitly use $\Omega$ terms. For example, matrix for $\frac{\pi}{2}$-pulse will look like:
\[
\begin{pmatrix}
	\Psi^\prime_1 \\	\Psi^\prime_2
\end{pmatrix} =
\frac{1}{\sqrt{2}} \begin{pmatrix}
	1 & -i \\ -i & 1
\end{pmatrix}
\begin{pmatrix}
	\Psi_1 \\ \Psi_2
\end{pmatrix}.
\]
More generally, rotation around the equatorial vector in Bloch sphere is described by the following matrix:
\[
\begin{pmatrix}
	\Psi^\prime_1 \\	\Psi^\prime_2
\end{pmatrix} =
\frac{1}{\sqrt{2}} \begin{pmatrix}
	1 & -i e^{-i \phi} \\ -i e^{i \phi} & 1
\end{pmatrix}
\begin{pmatrix}
	\Psi_1 \\ \Psi_2
\end{pmatrix}.
\]

After transformation to natural units and considering the above explanation of terms, we will get the following equations:
\[ i \frac{\partial \Psi_1}{\partial t} = \left(
	-\frac{\nabla^2}{2} + V_{ext} +
	g_{11} n_1 + g_{12} n_2 - \frac{i}{2} (l_{111} n_1^2 + l_{12} n_2)
\right) \Psi_1, \]
\[ i \frac{\partial \Psi_2}{\partial t} = \left(
	-\frac{\nabla^2}{2} + V_{ext} +
	g_{12} n_1 + g_{22} n_2 - \frac{i}{2} (l_{22} n_2 + l_{12} n_1) +
	\frac{\Delta}{\omega_\rho}
\right) \Psi_2, \]
where $l_{111}$, $l_{12}$ and $l_{22}$ are dimensionless loss terms:
\[ l_{ijk} = \gamma_{ijk} / l_\rho^6 \omega_{\rho},\, l_{ij} = \gamma_{ij} / l_\rho^3 \omega_{\rho}. \]

These coupled equations can be solved numerically with the same split-step Fourier propagation as we used to get single component ground state. Since the propagation is performed in real time now, and there are additional terms in the equations, differential and nonlinear operators will change:
\[ \hat{D} = i \frac{\nabla^2}{2}, \]
\[ \hat{N}_1 = -i \left( V_{ext} + g_{11} n_1 + g_{12} n_2 \right) - \frac{1}{2} \left( l_{111} n_1^2 + l_{12} n_2 \right), \]
\[
\hat{N}_2 = -i \left( V_{ext} + g_{12} n_1 + g_{22} n_2 + \frac{\Delta}{\omega_\rho} \right) -
\frac{1}{2} \left( l_{22} n_2 + l_{12} n_1 \right).
\]

\section*{Vacuum noise}

Since we are using pseudoclassical description of the condensate, we can increase accuracy of the model by taking into account quantum noise. According to \cite{PhysRevA.58.4824}, the quantum noise can be introduced as the addition of the following wave function to the initial conditions:
\[ \Psi_{noise}(\mathbf{r}) = \sum_{i=0}^{N_x} \sum_{j=0}^{N_y} \sum_{k=0}^{N_z} \frac{1}{2} \eta_{ijk} \phi_{ijk}(\mathbf{r}), \]
where $\eta_{ijk}$ are complex random numbers with independent normally distributed real and imaginary parts, and $\phi_{ijk}(\mathbf{r})$ are functions from a discrete position basis
\[ \phi_{ijk}(\mathbf{r}) = \delta(x - i\Delta x) \delta(y - j\Delta y) \delta(z - k\Delta z) / \sqrt{\Delta x \Delta y \Delta z} \]
with $\Delta x$, $\Delta y$ and $\Delta z$ being the steps of the spatial lattice. Practically, it means that, in order to take into account the quantum noise, we must add the field of random complex numbers to the initial state (in our case it would be GPE steady state for component $\vert1\rangle$ and zero for component $\vert2\rangle$). Real and imaginary parts of these fields must be Gaussian random numbers with variance equal to $1 / 2 \sqrt{\Delta x \Delta y \Delta z}$.

\section*{Implementation}

The model explained above is implemented using C++ and CUDA. Calculation is performed in three steps: first, GPE for one-component gas is solved, producing the steady state. Then there is an optional equilibration phase (corresponding to the time before first $\frac{\pi}{2}$ pulse), followed by the $\frac{\pi}{2}$ pulse and evolution phase. During the evolution phase, each step propagates system state for given time step and prepares data necessary for rendering. Preparation includes second $\frac{\pi}{2}$ pulse (which does not spoil original wave-functions, so that they could be propagated further), particle density calculation, projection on two orthogonal planes and writing these projections to textures for rendering.

Program uses $128\times32\times32$ lattice and calculates propagation in 1 or 4 ensembles (for quantum noise turned off or on, correspondingly), giving the following times for different stages:

\begin{itemize}
\item Steady state calculation: 3.4 s (20 $\mu$s time step)
\item Equilibration phase (if any): 12.9 s (20 ms with 40 $\mu$s time step) per ensemble
\item Evolution: 49.2 ms per step per ensemble
\end{itemize}

When number of ensembles multiplied by number of lattice points is low, calculation speed is affected mainly by rendering functions and decreases linearly with each additional ensemble; with lots of ensembles (or dense lattice), the bottleneck is FFT, and calculation speed depends on number of ensembles as $O(N\log{N})$.

\section*{Simulation results}

\begin{figure}
\begin{center}
\subfloat[Reference simulation]{\includegraphics[width=2.5in]{evolution_reference.png}}
\qquad
\subfloat[Split-step simulation]{\includegraphics[width=2.5in]{evolution_nolosses_40mus.png}}
\end{center}
\caption{Column density of the $\vert2\rangle$-component}
\label{evolution_vs_reference}
\end{figure}

The results produced by the program seems to be close to experiments and to reference simulations from \cite{anderson-2009-80}. As an example consider figure~\ref{evolution_vs_reference}, which shows the evolution of the density of $\vert2\rangle$-state. It contains the image from \cite{anderson-2009-80} and simulation result with disabled loss and detuning terms and the same model parameters:
\[ N = 150000 \]
\[ a_{11} = 100.40 a_0, a_{12} = 97.66 a_0, a_{22} = 95.00 a_0 \]
\[ f_x = 11.962 \textrm{ Hz}, f_y = f_z = 97.62 \textrm{ Hz} \]
\[ m = 87 m_p \textrm{ (Rubidium)}\]
Although there are some discrepancies, caused by different scales and the fact that reference image simulates condensate after expansion, the evolution of cloud structure goes similarly on both images.

\begin{figure}
\begin{center}
\subfloat[Reference simulation]{\includegraphics[width=2.5in]{visibility_reference.png}}
\qquad
\subfloat[Split-step simulation]{\includegraphics[width=2.5in]{visibility.pdf}}
\end{center}
\caption{Visibility over time and revival}
\label{visibility_vs_reference}
\end{figure}

Then we may try to enable loss and detuning terms and reproduce experimental data, namely, visibility. As can be seen on figure~\ref{visibility_vs_reference}, simulation results lie close to experimental points (but differ from interpolation made by experimenters, which is totally possible, since the interpolation is a pure speculation).

\bibliographystyle{plain}
\bibliography{refs}

\end{document}